# -*- coding: utf-8 -*-
"""Retail-Order-Data-Analysis .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13tKZMcPlgfvWS9pju-m5Fha4R_-YBg7Y
"""

!kaggle datasets download ankitbansal06/retail-orders -f orders.csv

import zipfile
with zipfile.ZipFile("/content/orders.csv.zip","r") as zip_ref:
    zip_ref.extractall("/content/")

import pandas as pd
df=pd.read_csv('/content/orders.csv')
df.head(5)

"""# **Handling Missing Values**"""

df.isnull().sum().sum()

df.fillna(0,inplace=True)

df.isnull().sum().sum()

"""# **Renaming Columns:**"""

df.rename({'Order Id':'Order_Id','Order Date':'Order_Date','Ship Mode':'Ship_Mode','Postal Code':'Postal_Code','Sub Category':'Sub_Category','Product Id':'Product_Id','cost price':'cost_price','List Price':'List_Price','Discount Percent':'Discount_Percent'},axis=1,inplace=True)

df.head(3)

"""# **Trimming Spaces**"""

cols = ['Order_Id','Order_Date','Ship_Mode','Segment','Country','City','State','Postal_Code','Region','Category','Sub_Category','Product_Id','cost_price','List_Price','Quantity','Discount_Percent']

for col in cols:
    df[col] = df[col].astype(str).str.strip()
df = df[cols]
df.head(3)

"""# **CALCULATING DISCOUNTS-**

# **Selling Price = Listed Price [(100âˆ’discount%)/100]**
"""

df['Discount_Percent'] = pd.to_numeric(df['Discount_Percent'], errors='coerce')
df['rough_column'] = (100 - df['Discount_Percent'])

df['rough_column_1']=df['rough_column']/100

df['List_Price'] = pd.to_numeric(df['List_Price'], errors='coerce')

df['Selling_Price']=df['List_Price']*df['rough_column_1']

df.drop(['rough_column','rough_column_1'],axis=1,inplace=True)

df.head(3)

"""# **Discount = List Price - Selling Price**"""

df['Discount']=df['List_Price']-df['Selling_Price']

df.head(3)

"""# **Profit = Selling Price - Cost Price**"""

df['cost_price'] = pd.to_numeric(df['cost_price'], errors='coerce')

df['Profit']=df['Selling_Price']-df['cost_price']
df.head(3)

df.to_csv('cleaned-orders.csv')

"""year, month and day extract from order_date using of to_datetime"""

df['Order_Date']=pd.to_datetime(df['Order_Date'])
df['year']=df['Order_Date'].dt.year
df['month']=df['Order_Date'].dt.month
df['day']=df['Order_Date'].dt.day
df.head(3)

"""Month name extract from month value using maping"""

dw_maping={

1:'January',
2:'February',
3:'March',
4:'April',
5:'May',
6:'June',
7:'July',
8:'August',
9:'September',
10:'October',
11:'November',
12:'December'
}
df['Month_name']=df['Order_Date'].dt.month.map(dw_maping)

df.head(3)

df.to_csv('cleaned-orders-1.csv')

"""# **process of localhost vscode or jupiter**

pip install mysql-connector-python

import mysql.connector

mydb=mysql.connector.connect

(

host='localhost',

user='root',

password='pass@123',

auth_plugin='mysql_native_password'

)
***************************************************
mycursor=mydb.cursor()

mycursor.execute('create database clearorder1')

mycursor.execute('create table orders')

mycursor.execute('show database')

for x in mycursor:
 print(x)

mycursor.execute('use clearorder1')

*********************************************************************************

mycusor=mydb.cursor()

mycursor.execute('select * from cleardata1')

myresult=mycursor.fetchall()

for x in myresult:
 print(x)
"""

# SQL

"""# **SQL**"""

import sqlite3
import pandas as pd

# File name of the uploaded CSV
csv_filename = "/content/cleaned-orders-1.csv"  # Replace this with the uploaded file name

# Load CSV into a pandas DataFrame
df = pd.read_csv(csv_filename)

# Connect to SQLite database (or create a new one)
conn = sqlite3.connect("example.db")
cursor = conn.cursor()

# Write DataFrame to SQLite table
table_name = "cleanedorders1"  # Specify your table name
df.to_sql(table_name, conn, if_exists="replace", index=False)

print(f"Table '{table_name}' created in SQLite database.")

"""# **Just count of all datas**"""

query = f"SELECT COUNT(*) FROM {table_name}"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **Average selling price**"""

query = f"SELECT product_id,avg(selling_price) FROM cleanedorders1;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **#Maximum Selling Price**"""

query = f"SELECT order_id,product_id,max(selling_price) FROM cleanedorders1;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""#Minimum Selling Price

"""

query = f"SELECT order_id,product_id,min(selling_price) FROM cleanedorders1;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""**Top-Selling Products: Identify the products that generate the highest revenue based on sale prices.**"""

query = f"SELECT row_number() over(order by product_id) as row,product_id, selling_price from cleanedorders1 where selling_price order by selling_price Desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **Monthly Sales Analysis**"""

# select order_date from cleanedorders1 where year order by year asc;

# SELECT count(*) order_date FROM cleanedorders1 WHERE month_name='January' and year='2022';
# SELECT order_date FROM cleanedorders1 WHERE month_name='January' and year='2022';

query = f"SELECT count(*) order_date FROM cleanedorders1 WHERE month_name='January' and year='2022';"
result = pd.read_sql_query(query, conn)

# Display the results
result

# Maximum Sales

# SELECT month_name,year,day,product_id,order_id,max(Selling_Price) FROM cleanedorders1;

# Minimum Sales

# SELECT month_name,year,day,product_id,order_id,min(Selling_Price) FROM cleanedorders1;

# Average Sales

# SELECT month_name,year,day,product_id,order_id,max(Selling_Price) FROM cleanedorders1;

query = f"SELECT month_name,year,max(Selling_Price) as sales FROM cleanedorders1 group by month order by sales desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **I) year-over-year sales to identify growth**"""

query = f"select Distinct year FROM cleanedorders1;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""**highest sales price**  - 2023 have highest sales price"""

query = f"SELECT year,sum(Selling_Price) as sales_price FROM cleanedorders1 group by year order by sales_price desc;"

result = pd.read_sql_query(query, conn)

# Display the results
result

"""***highest sale month of 2023*** - based on selling price"""

query = f"SELECT year,COUNT(order_id) as count_of_orders,month_name,sum(Selling_Price) FROM cleanedorders1 where year='2023' and month='2';"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""***highest orders placed on month of 2023*** - based on orders"""

query = f"SELECT year,COUNT(order_id) as count_of_orders,month_name,sum(Selling_Price) FROM cleanedorders1 where year='2023' and month='7';"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""***highest profit on month of 2023*** - based on Profit"""

query = f"SELECT COUNT(order_id),month_name,sum(profit),sum(selling_price) FROM cleanedorders1 where year='2023' and month='10';"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""**hint:-**

**highest selling price: - 2023:**

**highest profit : - 2022:**

**higest orders: - 2022:**

# **2023:**

***sum(Selling_Price) - 1120268.5 | sum(profit) - 103548.499 | count(order_id) - 4957***

# **2022:**

***sum(Selling_Price) - 1095590.2 |  sum(profit) - 101620.199 | count(order_id) - 5037***

# **II) year-over-year sales - decline in certain months**
"""

query = f"SELECT Selling_Price,year,month_name,COUNT(order_id) as total_declin_orders FROM cleanedorders1 WHERE selling_price<=0 group by month_name order by total_declin_orders desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""**total order decline both year of 2022 and 2023**"""

query = f"SELECT selling_Price,count(Order_Id) as total_order_Decline_both_years FROM cleanedorders1 WHERE selling_price<=0;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **Orders Decline of 2022**"""

query = f"SELECT Selling_Price,year,count(order_id) FROM cleanedorders1 WHERE selling_price<=0 and year='2022';"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **which month face highest decline of 2022**"""

query = f"SELECT Selling_Price,year,month_name, count(order_id) as counts FROM cleanedorders1 WHERE selling_price<=0 and year='2022' and month='11';"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **Orders decline of 2023**"""

query = f"SELECT Selling_Price,year, count(order_id) as counts FROM cleanedorders1 WHERE selling_price<=0 and year='2023';"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **which month face highest decline of 2023**"""

query = f"SELECT Selling_Price,year, count(order_id) as counts FROM cleanedorders1 WHERE selling_price<=0 and year='2023' and month='4';"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **III) Product Performance: **"""

query = f"SELECT row_number() over (order by product_id) as row, dense_rank() over (order by selling_price) as rank, product_id,quantity,max(profit),max(selling_price),min(discount) from cleanedorders1 group by product_id order by rank asc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **IV)Having**"""

query = f"SELECT row_number() over (order by product_id) as row, dense_rank() over (order by selling_price) as rank, product_id,quantity,max(profit),max(selling_price) as sale_price,min(discount) from cleanedorders1 group by product_id having max(selling_price)>=5000 order by sale_price asc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **V) Regional Sales Analysis:**"""

query = f"SELECT row_number() over (order by sum(profit)) as row, dense_rank() over (order by sum(selling_price)) as rank,region, count(quantity),sum(profit),sum(selling_price) as Total_Sales,sum(discount) from cleanedorders1 group by region order by Total_Sales desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **VI) Discount Analysis:**

# ** calculate the impact of discounts on sales**

**quantity_sold * (original_price - sales_price)**

orginal price is cost price
"""

query = f"SELECT order_date,product_id, quantity, cost_price,list_price,discount,selling_price,profit, (quantity * (cost_price - selling_price)) AS impact FROM  cleanedorders1 order by impact desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **Identify products with discounts greater than 20%**

dicount_percent = (cost_price - selling_price) / cost_price

"""

query = f"SELECT product_id,selling_price,discount,discount_percent FROM cleanedorders1 WHERE discount_percent > 0.20 order by discount_percent asc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **1.# Find top 10 highest revenue generating products**"""

query = f"SELECT product_id,selling_price from cleanedorders1 order by selling_price desc LIMIT 10;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""
# **2. # Find the top 5 cities with the highest profit margins**"""

query = f"SELECT city,sum(profit) as total_profit from cleanedorders1 group by city order by total_profit  desc limit 5;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""
# **3.# Calculate the total discount given for each category**"""

query = f"SELECT category,sum(discount) as discount_price from cleanedorders1 group by category;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **4.# Find the average sale price per product category**"""

query = f"SELECT category,avg(selling_price) from cleanedorders1 group by category;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **5.# Find the region with the highest average sale price**

"""

query = f"SELECT region,avg(selling_price) as avgsale from cleanedorders1 group by region order by avgsale desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""
# **6.# Find the total profit per category**"""

query = f"SELECT category,sum(profit) from cleanedorders1 group by category;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **7.# Identify the top 3 segments with the highest quantity of orders**

"""

query = f"SELECT segment,count(order_id) as orders from cleanedorders1 group by segment order by orders desc LIMIT 3;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **8.# Determine the average discount percentage given per region**"""

query = f"SELECT region,avg(discount_percent) as disc from cleanedorders1 group by region order by disc desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **9.# Find the product category with the highest total profit**

"""

query = f"SELECT category,sum(profit) as total_profit from cleanedorders1 group by category ORDER by total_profit desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **10.# Calculate the total revenue generated per year**

"""

query = f"SELECT year,sum(selling_price) as Revenue from cleanedorders1 group by year ORDER by Revenue desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **Second Half Questions**"""

# second half questions

df.head(5)

df1=df[['Order_Id','Order_Date','Ship_Mode','Segment','Country','City','State','Postal_Code','Region','Category','Sub_Category']]
df1.head(3)

df2=df[['Product_Id','cost_price','List_Price','Quantity','Discount_Percent','Selling_Price','Discount','Profit','year','month','day','Month_name']]
df2.head(3)

"""# **next 11 to 20 questions**

# **11) whats is primary key & Foreign Key**

# ***Primary Key***

primary key is major column of table its not create dublicate value mostly primary key used as a ID with not null option and somtimes add autoincrement options on sql table

*if you want to drop only primary key option not column

before create a primary key give constraint

eg:- alter table df1 CONSTRAINT PK_orders primary key(order_Id)

else

its enough ->  alter table df1 primary key(order_Id)

# ***Foreign key***

foreign key is child key its depended on primary key based

eg: star schmea
primary key in 1st table and foreign key in 2nd table,
its act like on connecting a bridge of both tables

when create a new row on 2nd table but value of foreign key not in primary key unable to create new row on 2nd table

eg: department in college they give primary value column of department as department id. students in college they also create primary key as student id and name, details, and connect to department to avoid duplicate and fast loading of date or easily update of database, create as foreign key connect to the primary key of department
"""

# 1) ALTER TABLE df1 ADD PRIMARY KEY (order_id);

#  ALTER TABLE df2 ADD COLUMN order_id INT;

# ALTER TABLE df2 ADD FOREIGN KEY(order_id) REFERENCES df1(order_id);

"""# **12) which region city have poor performance**

**a) which region, city poor performence of sales**
"""

query = f"SELECT region,city,min(selling_price) as sales from cleanedorders1 GROUP by city order by sales asc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""**b) which region, city poor performence of profit**"""

query = f"SELECT region,city,min(profit) as prof from cleanedorders1 GROUP by city order by prof asc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""**c) which region,city poor performence of orders**

"""

query = f"SELECT region,city,min(quantity) as qty from cleanedorders1 GROUP by city order by qty asc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **13) split two column as df1 and df2 and upload as sql database | create new colum for df2 2nd table as foreigh key**


"""

df.head(1)

df2['Order_Id'] = df1.assign(Order_Id=df1['Order_Id'].values)['Order_Id']

df2.head(3)

df1.head(3)

df1.to_csv('df1.csv')

df2.to_csv('df2.csv')

import sqlite3
import pandas as pd

# File name of the uploaded CSV
csv_filename1 = "/content/df1.csv"  # Replace this with the uploaded file name
csv_filename2 = "/content/df2.csv"  # This should point to the correct CSV file for df2

# Load CSV into a pandas DataFrame
df1 = pd.read_csv(csv_filename1)
df2 = pd.read_csv(csv_filename2) # Load data from the correct file for df2

# Connect to SQLite database (or create a new one)
conn = sqlite3.connect("example.db")
cursor = conn.cursor()

# Write DataFrame to SQLite table
table_name1 = "df1"  # Specify your table name
df1.to_sql(table_name1, conn, if_exists="replace", index=False)

table_name2 = "df2"  # Specify your table name
df2.to_sql(table_name2, conn, if_exists="replace", index=False)

print(f"Table '{table_name1}' created in SQLite database.")
print(f"Table '{table_name2}' created in SQLite database.")

# df2['Order_Id'] = df1.assign(Order_Id=df1['Order_Id'].values)['Order_Id']

# 1) ALTER TABLE df1 ADD PRIMARY KEY (order_id);
# 1) ALTER TABLE df1 constraints PK_order ADD PRIMARY KEY (order_id);

#  ALTER TABLE df2 ADD COLUMN order_id INT;

# ALTER TABLE df2 ADD FOREIGN KEY(order_id) REFERENCES df1(order_id);
# or
# ALTER TABLE df2 constraints FK_order ADD FOREIGN KEY(order_id) REFERENCES df1(order_id);

"""constraints FK_order - > its usefull when drop status of foreign key of that column otherwise can't delete that column because that primary key column wont allowed

# **14. join df1 and df2 two table using order id find as a discount from table 1 and city from table 2**
"""

df1=pd.read_csv('/content/df1.csv')
df2=pd.read_csv('/content/df2.csv')

df1.head(2)

df2.head(2)

"""select city from 1st table then take discount percent from 2nd table then from 1st table join 2nd table based on 1st primary key equal of 2nd table of foreign key thats all"""

query = f"SELECT df1.City,df2.Discount_Percent FROM df1 JOIN df2 ON df1.Order_Id = df2.Order_Id;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""SELECT df2.order_id,df2.Product_Id FROM df2 join df1 on df2.Order_Id = df1.Order_Id;

SELECT df1.city, df2.Discount_Percent
FROM df1
JOIN df2
ON df1.order_id = df2.order_id;

select city from 1st table then take discount percent from 2nd table then from 1st table join 2nd table based on 1st primary key equal of 2nd table of foreign key thats all

# **15. nested querry or sub querry**

select product_id from df2 where order_id in ( select order_id from df1 where order_id = '5')
"""

query = f"select product_id,Selling_Price from df2 where order_id in (select order_id from df1 where order_id = '5')"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""select selling_price,discount_percent,cost_price from df2 where order_id in ( select order_id from df1 where order_id = '20')

# **16.left join and right join**

eg: left join focus and marked on right table missing or null values

right join focus and marked on left table missing or null values

# **17.Seasonality:**

****Are there any seasonal trends in the data, such as higher sales during holidays or specific months?*****

SELECT month_name,year,day,sum(quantity) from cleanedorders1 GROUP by month_name order by quantity desc;
"""

query = f"SELECT month_name,year,day,sum(quantity) as qty from cleanedorders1 GROUP by month_name order by qty desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **seasonality based profit**"""

query = f"SELECT month_name,year,day,sum(profit) as profit from cleanedorders1 GROUP by month_name order by profit desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **18. Segment:**

# **a) maximum sales of each segment**
"""

query = f"SELECT segment,max(selling_price) as sales from cleanedorders1 GROUP by segment order by sales desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **b) total sales of each segment**"""

query = f"SELECT segment,sum(selling_price) as sales from cleanedorders1 GROUP by segment order by sales desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **c)total profit of each segment**"""

query = f"SELECT segment,sum(Profit) as profit from cleanedorders1 GROUP by segment order by profit desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **d) total quantaty of each segment**"""

query = f"SELECT segment,sum(quantity) as qty from cleanedorders1 GROUP by segment order by qty desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **19. Discount Effectiveness:**

**discounts or promotions impact sales volume and profitability**

# **min profit for discount**
"""

query = f"SELECT product_id,order_date,city,category,sub_category,quantity,selling_price,min(profit) as profit, (list_price - selling_price ) / selling_price * 100 AS discount FROM cleanedorders1 WHERE selling_price IS NOT NULL GROUP by quantity ORDER BY profit<0 asc"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **max profit for discount**"""

query = f"SELECT product_id,order_date,city,category,sub_category,quantity,selling_price,max(profit) as profit, (list_price - selling_price ) / selling_price * 100 AS discount FROM cleanedorders1 WHERE selling_price GROUP by quantity ORDER BY profit>0 DESC"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **quantaty increase for discount**

"""

query = f"SELECT product_id,order_date,city,category,sub_category,quantity,selling_price,profit, (list_price - selling_price ) / selling_price * 100 AS discount FROM cleanedorders1 WHERE selling_price IS NOT NULL GROUP by quantity ORDER BY quantity>0 DESC"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **quantaty increase for discount using having method**

"""

query = f"SELECT product_id,order_date,city,category,sub_category,quantity,selling_price,profit, (list_price - selling_price ) / selling_price * 100 AS discount FROM cleanedorders1 WHERE selling_price IS NOT NULL GROUP by quantity having quantity>0 order by quantity desc"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **20) ship mode prefered most**

"""

query = f"SELECT ship_mode,sum(quantity) as qty from cleanedorders1 GROUP by ship_mode order by qty desc;"
result = pd.read_sql_query(query, conn)

# Display the results
result

"""# **Streamlit**"""

# streamlit

!pip install -q streamlit

ipv4 = !curl ipv4.icanhazip.com
ipv4

# Commented out IPython magic to ensure Python compatibility.
# %%writefile streamlit5_app.py
# 
# import streamlit as st
# import sqlite3
# import pandas as pd
# 
# # Streamlit app title
# st.title("Retail Order Data Analysis (1st-Project)")
# 
# # File uploader in Streamlit
# # File name of the uploaded CSV (replace with the actual uploaded file)
# csv_filename = "/content/cleaned-orders-1.csv"  # Replace with the uploaded file name
# csv_filename1 = "/content/df1.csv"
# csv_filename2 = "/content/df2.csv"
# 
# # Load CSV into a pandas DataFrame
# df = pd.read_csv(csv_filename)
# df1 = pd.read_csv(csv_filename1)
# df2 = pd.read_csv(csv_filename2)
# 
# # Connect to SQLite database (or create a new one)
# conn = sqlite3.connect("example.db")
# cursor = conn.cursor()
# 
# # Write DataFrame to SQLite table (replace with your table name)
# table_name = "cleanedorders1"
# table_name1 = "df1"
# table_name2 = "df2"
# 
# df.to_sql(table_name, conn, if_exists="replace", index=False)
# df1.to_sql(table_name1, conn, if_exists="replace", index=False)
# df2.to_sql(table_name2, conn, if_exists="replace", index=False)
# 
# st.success(f"Tables '{table_name}', '{table_name1}', and '{table_name2}' created in SQLite database.")
# 
# 
# # Define two sets of queries as dictionaries with descriptive names
# query_sets = {
#     "Sales Analysis Queries": {
#         "Top-Selling Products": "SELECT row_number() over(order by product_id) as row, product_id, selling_price FROM cleanedorders1 ORDER BY selling_price DESC;",
#         "Monthly Sales Analysis": "SELECT month_name, year, max(Selling_Price) as sales FROM cleanedorders1 GROUP BY month ORDER BY sales DESC;",
#         "Product Performance - using Group By Method": "SELECT row_number() over (order by product_id) as row, dense_rank() over (order by selling_price) as rank, product_id, quantity, max(profit), max(selling_price), min(discount) FROM cleanedorders1 GROUP BY product_id ORDER BY rank ASC;",
#         "Product Performance - using Group By and Having Method": "SELECT row_number() over (order by product_id) as row, dense_rank() over (order by selling_price) as rank, product_id,quantity,max(profit),max(selling_price) as sale_price,min(discount) from cleanedorders1 group by product_id having max(selling_price)>=5000 order by sale_price asc;",
#     },
#     "Impact Analysis Queries": {
#         "Regional Sales Analysis": "SELECT row_number() over (order by sum(profit)) as row, dense_rank() over (order by sum(selling_price)) as rank, region, count(quantity), sum(profit), sum(selling_price) as Total_Sales, sum(discount) FROM cleanedorders1 GROUP BY region ORDER BY Total_Sales DESC;",
#         "Discount Analysis": "SELECT order_date, product_id, quantity, cost_price, list_price, discount, selling_price, profit, (quantity * (cost_price - selling_price)) AS impact FROM cleanedorders1 ORDER BY impact DESC;",
#     },
#     "year-over-year sales to identify growth": {
#         "highest sales price of year": "SELECT year,sum(Selling_Price) as sales_price FROM cleanedorders1 group by year order by sales_price desc;",
#         "highest sale month of 2023 ": "SELECT year,COUNT(order_id) as count_of_orders,month_name,sum(Selling_Price) FROM cleanedorders1 where year='2023' and month='2';",
#         "highest orders placed on month of 2023 ": "SELECT year,COUNT(order_id) as count_of_orders,month_name,sum(Selling_Price) FROM cleanedorders1 where year='2023' and month='7';",
#         "highest profit on month of 2023": "SELECT COUNT(order_id),month_name,sum(profit),sum(selling_price) FROM cleanedorders1 where year='2023' and month='10';",
#     },
#     "year-over-year sales - decline in certain months": {
#         "decline sales month of year": "SELECT Selling_Price,year,month_name,COUNT(order_id) as total_declin_orders FROM cleanedorders1 WHERE selling_price<=0 group by month_name order by total_declin_orders desc;",
#         "total order decline both year of 2022 and 2023": "SELECT selling_Price,count(Order_Id) as total_order_Decline_both_years FROM cleanedorders1 WHERE selling_price<=0;",
#         "Orders Decline of 2022 ": "SELECT Selling_Price,year,count(order_id) FROM cleanedorders1 WHERE selling_price<=0 and year='2022';",
#         "which month face highest decline of 2022": "SELECT Selling_Price,year,month_name, count(order_id) as counts FROM cleanedorders1 WHERE selling_price<=0 and year='2022' and month='11';",
#         "Orders Decline of 2023 ": "SELECT Selling_Price,year,count(order_id) FROM cleanedorders1 WHERE selling_price<=0 and year='2023';",
#         "which month face highest decline of 2023": "SELECT Selling_Price,year,month_name, count(order_id) as counts FROM cleanedorders1 WHERE selling_price<=0 and year='2023' and month='3';",
# 
#     },
#      "First 10 Questions": {
#         "1.# Find top 10 highest revenue generating products": "SELECT product_id,selling_price from cleanedorders1 order by selling_price desc LIMIT 10;",
#         "2.# Find the top 5 cities with the highest profit margins": "SELECT city,sum(profit) as total_profit from cleanedorders1 group by city order by total_profit  desc limit 5;",
#         "3.# Calculate the total discount given for each category": "SELECT category,sum(discount) as discount_price from cleanedorders1 group by category;",
#         "4.# Find the average sale price per product category": "SELECT category,avg(selling_price) from cleanedorders1 group by category;",
#         "5.# Find the region with the highest average sale price": "SELECT region,avg(selling_price) as avgsale from cleanedorders1 group by region order by avgsale desc;",
#         "6.# Find the total profit per category": "SELECT category,sum(profit) from cleanedorders1 group by category;",
#         "7.# Identify the top 3 segments with the highest quantity of orders": "SELECT segment,count(order_id) as orders from cleanedorders1 group by segment order by orders desc LIMIT 3;",
#         "8.# Determine the average discount percentage given per region ": "SELECT region,avg(discount_percent) as disc from cleanedorders1 group by region order by disc desc;",
#         "9.# Find the product category with the highest total profit ": "SELECT category,sum(profit) as total_profit from cleanedorders1 group by category ORDER by total_profit desc;",
#         "10.# Calculate the total revenue generated per year": "SELECT year,sum(selling_price) as Revenue from cleanedorders1 group by year ORDER by Revenue desc;",
#     },
#     "11 to 20 Questions using primary and foreign key join table process": {
#         "11.# which region city have poor performance": "SELECT region,city,min(selling_price) as sales from cleanedorders1 GROUP by city order by sales asc;",
#         "12.# join df1 and df2 two table using order id find as a discount from table 1 and city from table 2": "SELECT df1.City,df2.Discount_Percent FROM df1 JOIN df2 ON df1.Order_Id = df2.Order_Id;",
#         "13.# nested querry or sub querry give order ID Value Find Product ID": "select product_id,Selling_Price from df2 where order_id in (select order_id from df1 where order_id = '5');",
#         "14.# Seasonality bases Profit": "SELECT month_name,year,day,sum(quantity) as qty from cleanedorders1 GROUP by month_name order by qty desc;",
#         "15.# Segment": "SELECT segment,max(selling_price) as sales from cleanedorders1 GROUP by segment order by sales desc;",
#         "16.# Discount Effectiveness": "SELECT product_id,order_date,city,category,sub_category,quantity,selling_price,max(profit) as profit, (list_price - selling_price ) / selling_price * 100 AS discount FROM cleanedorders1 WHERE selling_price GROUP by quantity ORDER BY profit>0 DES;",
#         "17.# quantaty increase for discount using having method": "SELECT product_id,order_date,city,category,sub_category,quantity,selling_price,profit, (list_price - selling_price ) / selling_price * 100 AS discount FROM cleanedorders1 WHERE selling_price IS NOT NULL GROUP by quantity having quantity>0 order by quantity desc;",
#         "18.# ship mode prefered most": "SELECT ship_mode,sum(quantity) as qty from cleanedorders1 GROUP by ship_mode order by qty desc;",
#         "19.# Identify products with discounts greater than 20%": "SELECT product_id,selling_price,discount,discount_percent FROM cleanedorders1 WHERE discount_percent > 0.20 order by discount_percent asc;",
#         "20.# Are there any seasonal trends in the data, such as higher sales during holidays or specific months?": "SELECT month_name,year,day,sum(quantity) as qty from cleanedorders1 GROUP by month_name order by qty desc;",
# 
#      },
# }
# 
# # Create a dropdown to select the query set
# selected_query_set_name = st.selectbox("Select Query Set:", list(query_sets.keys()))
# selected_query_set = query_sets[selected_query_set_name]
# 
# # Create a dropdown to select queries within the selected set
# selected_query_name = st.selectbox("Select Query:", list(selected_query_set.keys()))
# selected_query = selected_query_set[selected_query_name]
# 
# # Execute the selected query based on user choice
# if st.button("Execute Query"):
#     # Fetch results and convert to DataFrame
#     result = pd.read_sql_query(selected_query, conn)
# 
#     # Display the query results
#     st.write("Query results:")
#     st.dataframe(result)
# 
# # Close the connection
# conn.close()
#

# !streamlit run streamlit5_app.py  &>/content/logs.txt & npx localtunnel --port 8501

